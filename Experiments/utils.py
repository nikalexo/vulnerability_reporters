from IPython.display import set_matplotlib_formats
set_matplotlib_formats('pdf', 'svg')
import matplotlib.pyplot as plt 
import powerlaw, math
import numpy as np
from matplotlib import rc
import csv
import json

def get_rep_num_cves(rep2info, project):
    rep2num = dict()
    for rep in rep2info:
        templist = []
        for cve in rep2info[rep]['cves']:
            if project == 'all' or cve in project:
                if cve not in templist:
                    templist.append(cve)
        if len(templist) > 0:
            rep2num[rep] = len(templist)

    sorted_dict = {k: v for k, v in sorted(rep2num.items(), key=lambda item: item[1], reverse = True)}
    
    num_list = []
    rep_list = []
    for rep in sorted_dict:
        num_list.append(sorted_dict[rep])
        rep_list.append(rep)
       
    return num_list, rep_list

def power_law_test(mydata, project):
    N = len(mydata)
    
    results_str = project + "\n"
    
    results_str += "data length = " + str(N) + "\n"

    results=powerlaw.Fit(mydata, discrete=True, estimate_discrete=False, xmin=1)
    results_str += "alpha = " + str(results.power_law.alpha) + "\n"
    results_str += "xmin = " + str(results.power_law.xmin) + "\n"
    results_str += "xmax = " + str(results.power_law.xmax) + "\n"
    results_str += "sigma = " + str(results.power_law.sigma) + "\n"
    results_str += "D = " + str(results.power_law.D) + "\n"
    results_str += "FOR TRUNCATED:" + "\n"
    results_str += "alpha = " + str(results.truncated_power_law.alpha) + "\n"
    results_str += "xmin = " + str(results.truncated_power_law.xmin) + "\n"
    results_str += "xmax = " + str(results.truncated_power_law.xmax) + "\n"
    results_str += str(results.power_law.discrete) + "\n"
    results_str += "lognormal mu: " + str(results.lognormal.mu) + "\n"
    results_str += "lognormal sigma: " + str(results.lognormal.sigma) + "\n"

    fig = results.plot_ccdf(color = 'darkblue', linestyle='-', label='data - ' + project)
    results.power_law.plot_ccdf(color = 'darkgreen', ax=fig, label='power-law fit')
    results.truncated_power_law.plot_ccdf(color = 'red', ax=fig, label='truncated power-law fit')
    #results.lognormal_positive.plot_ccdf(color = 'yellow', ax=fig)
    results.lognormal.plot_ccdf(color = 'brown', ax=fig, label='lognormal fit')
    #results.exponential.plot_ccdf(color = 'orange', ax=fig)

    plt.ylabel('ccdf')
    plt.xlabel('Vulnerabilities - ' + project)
    fig.legend()
    plt.savefig("./results/reporter_distribution/ccdf_" + project, format="pdf",bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    R, p=results.distribution_compare('power_law','exponential')
    results_str += "Exponential: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('power_law','stretched_exponential')
    results_str += "Stretched exponential: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('power_law','truncated_power_law')
    results_str += "Power law truncated: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('power_law','lognormal_positive')
    results_str += "Lognormal positive: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('power_law','lognormal')
    results_str += "Lognormal: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('truncated_power_law', 'stretched_exponential')
    results_str += "Truncated vs stretched expo: " + str(R) + " " + str(p) + "\n"
    R, p=results.distribution_compare('truncated_power_law', 'lognormal')
    results_str += "Truncated vs lognormal: "+ str(R) + " " + str(p) + "\n"
    
    p_value_005 = 1.36 / math.sqrt(N)
    p_value_010 = 1.22 / math.sqrt(N)
    #powerlaw.plot_pdf(mydata, color='b')
    results_str += "p_value_005: " + str(p_value_005) + "\n"
    results_str += "p_value_010: " + str(p_value_010) + "\n"
    # p-values are a scam!!!
    # Power-law looks like a possible fit, however we cannot statistically rule out other heavy-tailed distributions
    a = sum(mydata[:(math.floor(len(mydata)*0.2))])
    b = sum(mydata)
    results_str += "Sum top 20%: " + str(a) + "\n"
    results_str += "Sum all: " + str(b) + "\n"
    results_str += "Sum top 20% devided by sum all: " + str(a/b) + "\n\n"
    # Power-law with some exponential cut-off can fit the data. We also see the 80-20 rule (73-27)
    
    return results_str

def dist_plot(filename, values):
    fig = plt.figure()
    fig.subplots_adjust(top=0.5)
    ax1 = fig.add_subplot(121)
    ax1.set_ylabel('# reports')
    t = range(1,len(values)+1)
    line, = ax1.plot(values)

    ax2 = fig.add_subplot(122)
    #ax2.set_ylabel('# reports')
    t = range(1,len(values)+1)
    line, = ax2.loglog(values)
    plt.savefig(filename, format = "pdf",bbox_inches="tight")
    plt.cla()
    plt.clf()
    
# Extract the top X reporters for a given project
def get_top_X_reps(rep2info, project, X):
    rep2num = dict()
    for rep in rep2info:
        templist = []
        for cve in rep2info[rep]['cves']:
            if project == 'all' or cve in project:
                templist.append(cve)
            if len(templist) > 0:
                rep2num[rep] = len(templist)

    sorted_dict = {k: v for k, v in sorted(rep2num.items(), key=lambda item: item[1], reverse = True)}
    rep_list = []
    for rep in sorted_dict:
        if rep2info[rep]['type'] != ['c'] and rep2info[rep]['type'] != ['t'] and rep2info[rep]['type'] != 'c' and rep2info[rep]['type'] != 't' and rep != 'Not known':
            rep_list.append(rep)
        
    return(rep_list[:X])

def plot_top_X(begin, end, proj_name, X, cve2year, rep2info, project):
    proj_topX = get_top_X_reps(rep2info, project, X)
    topX_2year = dict()
    
    n = end - begin + 1
    years = range(begin,end+1)
    
    for name in proj_topX:
        topX_2year[name] = [0] * n

    for name in proj_topX:
        for cve in rep2info[name]['cves']:
            year = cve2year[cve]
            if year-begin > -1:
                topX_2year[name][year-begin] += 1

    for name in proj_topX:
        plt.plot(years, topX_2year[name], label=name)
        plt.xticks(np.arange(begin, end+1, step=2))
        plt.legend()
    
    plt.savefig("./results/reporter_reporting_rate/top_" + str(X) + "_reps_per_year_" + proj_name + ".pdf", format="pdf",bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Now plot everything centered around the peak
    for name in proj_topX:
        v_max = max(topX_2year[name])
        i_max = topX_2year[name].index(v_max)
        i_last = 20
        jj = 0
        for year in topX_2year[name]:
            if year != 0:
                i_last = jj
            jj += 1
        # print(i_max, i_last)
        temp_list = [0] * (20-i_max) + topX_2year[name] + [0] * i_max
        plt.plot(temp_list, label=name)
        plt.legend()
        
    plt.savefig("./results/reporter_reporting_rate/top_" + str(X) + "_reps_per_year_centered_" + proj_name + ".pdf", format="pdf",bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Here check for a drop-off effect --> their "final" report within 2 years of the peak. "Final" until now if at least one year with no report.
    
    
    return(topX_2year)

def get_top_X(begin, end, X, rep2info, project, cve2year):
    proj_topX = get_top_X_reps(rep2info, project, X)
    topX_2year = dict()
    n = end - begin + 1
    for name in proj_topX:
        topX_2year[name] = [0] * n

    for name in proj_topX:
        for cve in rep2info[name]['cves']:
            year = cve2year[cve]
            if year - begin > -1:
                topX_2year[name][year-begin] += 1
    return(topX_2year)

def compute_stats(begin, end, project, X, rep2info, cve2year):  
    topX = get_top_X(begin, end, X, rep2info, project, cve2year)

    # Time between first and last report
    time_first_last = []
    
    # Time between first report and peak
    time_first_peak = []
    
    # Time between peak and last report    
    time_peak_last = []
    
    
    for rep in topX:
        print(rep)
        start = 0
        end = 0
        peak = topX[rep].index(max(topX[rep]))
        for i in range(len(topX[rep])):
            if start == 0 and topX[rep][i] != 0:
                start = i
            if topX[rep][i] != 0:
                end = i
        t = end - start + 1
        t1 = peak - start
        t2 = end - peak
        time_first_last.append(t)
        time_first_peak.append(t1)
        time_peak_last.append(t2)

    return (time_first_last, time_first_peak, time_peak_last)

# Here we will use the mapping of cwe's to top-level categories
def manual_cve_mappings(cwe: str) -> int:
        """Mapps CWE-ID to a top-level category.
        1 - Memory and Resource Management
        2 - Input Validation and Sanitization
        3 - Code Development Quality
        4 - Security Measures
        5 - Others
        6 - Concurrency
        CWEs that are not included return None, as well as the CWE \'NVD-noinfo\'"""
        cwe = cwe[4:]
        mappings = {'20': 2, '189': 4, '119': 1, '125': 1, '399': 1, 'CWE-Other': 5, '200': 4, '476': 1, '264': 4,
                    '416': 1, '835': 3, 'CWE-noinfo': None, '362': 6, '400': 1, '787': 1, '772': 1, '310': 4, '190': 1,
                    '74': 2, '17': 3, '284': 4, '415': 1, '369': 3, '19': 5, '834': 3, '79': 4, '754': 5, '674': 3,
                    '120': 1, '94': 2, '388': 5, '269': 4, '254': 4, '129': 2, '287': 4, '617': 3, '276': 4, '404': 1,
                    '134': 5, '862': 4, '320': 4, '89': 2, '347': 4, '682': 3, '16': 5, '665': 5, '755': 5, '732': 4,
                    '311': 4, '770': 1, '252': 5, '534': 5, '704': 5, '22': 2, '532': 5, '193': 3, '843': 5, '391': 5,
                    '191': 1, '59': 2, '763': 1, '358': 4, '285': 4, '863': 4, '77': 2, '327': 4, '330': 5, '295': 5,
                    '352': 5}
        try:
            return mappings[cwe]
        except:
            return None

def merge_affs(aff_list, aff2cves):

    # Keep the first name in the list
    
    if len(aff_list) < 2:
        print('Nothing to merge')
        return
    
    keep = aff_list[0]
    remove_list = aff_list[1:]
    
    for aff in remove_list:
        if aff in aff2cves.keys():
            for cve in aff2cves[aff]:
                if keep not in aff2cves.keys():
                    aff2cves[keep] = []
                if cve not in aff2cves[keep]:
                    aff2cves[keep].append(cve)
                
    for aff in remove_list:
        if aff in aff2cves.keys():
            del aff2cves[aff]

def fill_standards(projects, collections):
    severities_standard = [[] for y in range(len(projects))] # e.g. ["blocker", "critical", "major", "normal", "minor", "trivial", "enhancement"]
    resolutions_standard = [[] for y in range(len(projects))] # e.g. ["FIXED", "INVALID", "WONTFIX", "DUPLICATE", "WORKSFORME", "MOVED", "NOTABUG", "NOTOURBUG", "INSUFFICIENTDATA"]
    status_standard = [[] for y in range(len(projects))] # e.g. ["UNCONFIRMED", "CONFIRMED", "IN_PROGESS", "RESOLVED", "VERIFIED"]
    type_standard = [[] for y in range(len(projects))]
    
    for p in range(len(projects)):
        print("Fill possible values for project:", projects[p])
        temp_collection = []
        for collection in collections[p]:
            temp_collection.append(collection)
        counter = 0 
        for collection in temp_collection:
            severity = collection.find_one({"severity": {"$exists":True}})
            resolution = collection.find_one({"resolution": {"$exists":True}})
            status = collection.find_one({"status": {"$exists":True}})
            type_ = collection.find_one({"type": {"$exists":True}})

            for bug in collection.find({}):
                # check severity        
                if severity != None:
                    try:
                        index = severities_standard[p].index(str(bug['severity']))
                    except:
                        severities_standard[p].append(bug['severity'])
                # check resolution        
                if resolution != None:
                    try:
                        index = resolutions_standard[p].index(bug['resolution'])
                    except:
                        resolutions_standard[p].append(bug['resolution'])
                # check status        
                if status != None:
                    try:
                        index = status_standard[p].index(bug['status'])
                    except:
                        status_standard[p].append(bug['status'])
                # check type      
                if type_ != None:
                    try:
                        index = type_standard[p].index(bug['type'])
                    except:
                        type_standard[p].append(bug['type'])
    return (severities_standard, resolutions_standard, status_standard, type_standard)

def store_results_bugs_reporters(projects, bugs_of_reps,
        severities_standard, resolutions_standard, status_standard, type_standard, key_words,
        severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep,
        bugs_in_db, severities_db, resolutions_db, status_db, type_db, key_words_db, key_words_num_db, 
        percentage, path):  
    # Write severity results
    with open(path + "/statistics_severity_" + str(percentage) + ".csv", "w") as f:
        writer = csv.writer(f)
        for p in range(len(projects)):
            row = ["Project"]
            for s in severities_standard[p]:
                s += "-Reporters"
                row.append(s)
            for s in severities_standard[p]:
                s += "-Rest"
                row.append(s)
            writer.writerow(row)

            row = [projects[p]]
            row.extend(severities_reps[p])
            for x in range(len(severities_standard[p]) - len(severities_reps[p])):
                row.append(0)
            row.extend(severities_db[p])
            #print(row)
            writer.writerow(row)
    # Write resolutions results
    with open(path + "/statistics_resolution_" + str(percentage) + ".csv", "w") as f:
        writer = csv.writer(f)
        for p in range(len(projects)):
            row = ["Project"]
            for s in resolutions_standard[p]:
                s += "-Reporters"
                row.append(s)
            for s in resolutions_standard[p]:
                s += "-Rest"
                row.append(s)
            writer.writerow(row)

            row = [projects[p]]
            row.extend(resolutions_reps[p])
            for x in range(len(resolutions_standard[p]) - len(resolutions_reps[p])):
                row.append(0)
            row.extend(resolutions_db[p])
            #print(row)
            writer.writerow(row)
    # Write status results
    with open(path + "/statistics_status_" + str(percentage) + ".csv", "w") as f:
        writer = csv.writer(f)
        for p in range(len(projects)):
            row = ["Project"]
            for s in status_standard[p]:
                s += "-Reporters"
                row.append(s)
            for s in status_standard[p]:
                s += "-Rest"
                row.append(s)
            writer.writerow(row)

            row = [projects[p]]
            row.extend(status_reps[p])
            for x in range(len(status_standard[p]) - len(status_reps[p])):
                row.append(0)
            row.extend(status_db[p])
            #print(row)
            writer.writerow(row)
    # Write type results
    with open(path + "/statistics_type_" + str(percentage) + ".csv", "w") as f:
        writer = csv.writer(f)
        for p in range(len(projects)):
            row = ["Project"]
            for s in type_standard[p]:
                s += "-Reporters"
                row.append(s)
            for s in type_standard[p]:
                s += "-Rest"
                row.append(s)
            writer.writerow(row)

            row = [projects[p]]
            row.extend(type_reps[p])
            for x in range(len(type_standard[p]) - len(type_reps[p])):
                row.append(0)
            row.extend(type_db[p])
            #print(row)
            writer.writerow(row)
    # Write key words results
    with open(path + "/statistics_key_words_" + str(percentage) + ".csv", "w") as f:
        writer = csv.writer(f)
        for p in range(len(projects)):
            row = ["Project"]
            for s in key_words:
                s += "-Reporters"
                row.append(s)
            row.append("all-Reporters")
            row.append("counter bugs-Reporters")
            row.append("sum all bugs-Reporters")
            for s in key_words:
                s += "-Rest"
                row.append(s)
            row.append("all-Rest")
            row.append("counter bugs-Rest")
            row.append("sum all bugs-Rest")
            writer.writerow(row)

            row = [projects[p]]
            row.extend(key_words_rep[p])
            row.append(sum(key_words_rep[p]))
            row.append(key_words_num_rep[p])
            row.append(len(bugs_of_reps[p]))
            row.extend(key_words_db[p])
            row.append(sum(key_words_db[p]))
            row.append(key_words_num_db[p])
            row.append(len(bugs_in_db[p]))
            #print(row)
            writer.writerow(row)

def check_reporters(percentage, projects, severities_standard, 
            resolutions_standard, status_standard, type_standard, key_words, 
            rep2cves_files, rep2non_cve_bugs_files, collections):
    bugs_of_reps = [[] for y in range(len(projects))]
    severities_reps = [[] for y in range(len(projects))]
    resolutions_reps = [[] for y in range(len(projects))]
    status_reps = [[] for y in range(len(projects))]
    type_reps = [[] for y in range(len(projects))]
    key_words_rep = [[0 for x in range(len(key_words))] for y in range(len(projects))]
    key_words_num_rep = [0 for y in range(len(projects))]

    for p in range(len(projects)):
        print("Check bugs of reporters for project:", projects[p])
        severities_reps[p] = [0 for y in range(len(severities_standard[p]))]
        resolutions_reps[p] = [0 for y in range(len(resolutions_standard[p]))]
        status_reps[p] = [0 for y in range(len(status_standard[p]))]
        type_reps[p] = [0 for y in range(len(type_standard[p]))]
        
        with open(rep2non_cve_bugs_files[p]) as jf:
            rep2non_cve_bugs = json.load(jf)

        with open(rep2cves_files[p]) as jf:
            rep2cves = json.load(jf)
        rep2cves = sorted(rep2cves.items(), reverse=True, key=lambda item: len(item[1]))

        max_pos = int(len(rep2cves)*percentage)
        reporters = []
        for k, _ in rep2cves[:max_pos]:
            reporters.append(k)

        temp_collection = []
        for collection in collections[p]:
            temp_collection.append(collection)

        severity = temp_collection[0].find_one({"severity": {"$exists":True}})
        resolution = temp_collection[0].find_one({"resolution": {"$exists":True}})
        status = temp_collection[0].find_one({"status": {"$exists":True}})
        type_ = temp_collection[0].find_one({"type": {"$exists":True}})
        description = temp_collection[0].find_one({"description": {"$exists":True}})
        
        counter = 0
        for rep in rep2non_cve_bugs.keys():
            if rep in reporters:
                counter += 1
                #print("Checking reporter", counter)
                for bug in rep2non_cve_bugs[rep]:
                    if not str(bug) in bugs_of_reps[p]:
                        bugs_of_reps[p].append(str(bug))
                    bug_db = None
                    for collection in temp_collection:
                        if projects[p] == "PHP":
                            bug_temp = collection.find_one({"id":bug})
                        else:
                            bug_temp = collection.find_one({"id":int(bug)})
                        if bug_temp != None:
                            bug_db = bug_temp
                            break
                        else:
                            continue
                    # check severity        
                    if bug_db != None and severity != None:
                        index = severities_standard[p].index(str(bug_db['severity']))
                        severities_reps[p][index] += 1
                    # check resolution        
                    if bug_db != None and resolution != None:
                        index = resolutions_standard[p].index(bug_db['resolution'])
                        resolutions_reps[p][index] += 1
                    # check status       
                    if bug_db != None and status != None:
                        index = status_standard[p].index(bug_db['status'])
                        status_reps[p][index] += 1
                    # check type      
                    if bug_db != None and type_ != None:
                        index = type_standard[p].index(bug_db['type'])
                        type_reps[p][index] += 1
                    # check keywords - description
                    inserted = False
                    if bug_db != None and description != None:
                        for i in range(len(key_words)):
                            if key_words[i] in bug_db['description']:
                                key_words_rep[p][i] += 1
                                if not inserted:
                                    inserted = True
                                    key_words_num_rep[p] += 1
                    elif bug_db != None and (projects[p] == "Apache" or projects[p] == "Linux"):       # first comment = description
                        try:
                            for i in range(len(key_words)):
                                if bug_db['comments'] != None and key_words[i] in bug_db['comments'][0]["text"]:
                                    key_words_rep[p][i] += 1
                                    if not inserted:
                                        inserted = True
                                        key_words_num_rep[p] += 1
                        except:
                            print("Error during key word search!")
    return (bugs_of_reps, severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep)

def check_rest(bugs_of_reps, projects, severities_standard, 
            resolutions_standard, status_standard, type_standard, 
            key_words, collections):   
    bugs_in_db = [[] for x in range(len(projects))]
    severities_db = [[] for y in range(len(projects))]
    resolutions_db = [[] for y in range(len(projects))]
    status_db = [[] for y in range(len(projects))]
    type_db = [[] for y in range(len(projects))]
    key_words_db = [[0 for x in range(len(key_words))] for y in range(len(projects))]
    key_words_num_db = [0 for y in range(len(projects))]

    for p in range(len(projects)):
        print("Check bugs of rest for project:", projects[p])
        severities_db[p] = [0 for y in range(len(severities_standard[p]))]
        resolutions_db[p] = [0 for y in range(len(resolutions_standard[p]))]
        status_db[p] = [0 for y in range(len(status_standard[p]))]
        type_db[p] = [0 for y in range(len(type_standard[p]))]
        
        temp_collection = []
        for collection in collections[p]:
            temp_collection.append(collection)

        severity = temp_collection[0].find_one({"severity": {"$exists":True}})
        resolution = temp_collection[0].find_one({"resolution": {"$exists":True}})
        status = temp_collection[0].find_one({"status": {"$exists":True}})
        type_ = temp_collection[0].find_one({"type": {"$exists":True}})
        description = temp_collection[0].find_one({"description": {"$exists":True}})
        
        counter = 0 
        for collection in temp_collection:
            for bug in collection.find({}):
                counter += 1
                #print("Checking bug", counter)
                if not bug['id'] in bugs_in_db[p] and not str(bug['id']) in bugs_of_reps[p]:
                    bugs_in_db[p].append(bug['id'])

                    # check severity        
                    if severity != None:
                        index = severities_standard[p].index(str(bug['severity']))
                        severities_db[p][index] += 1
                    # check resolution        
                    if resolution != None:
                        index = resolutions_standard[p].index(bug['resolution'])
                        resolutions_db[p][index] += 1
                    # check status        
                    if status != None:
                        index = status_standard[p].index(bug['status'])
                        status_db[p][index] += 1
                    # check type      
                    if type_ != None:
                        index = type_standard[p].index(bug['type'])
                        type_db[p][index] += 1
                    # check keywords - description
                    inserted = False
                    if description != None:
                        for i in range(len(key_words)):
                            if key_words[i] in bug['description']:
                                key_words_db[p][i] += 1
                                if not inserted:
                                    inserted = True
                                    key_words_num_db[p] += 1
                    elif projects[p] == "Apache" or projects[p] == "Linux":       # first comment = description
                        try:
                            for i in range(len(key_words)):
                                if bug['comments'] != None and key_words[i] in bug['comments'][0]["text"]:
                                    key_words_db[p][i] += 1
                                    if not inserted:
                                        inserted = True
                                        key_words_num_db[p] += 1
                        except:
                            print("Error during key word search!")
    return (bugs_in_db, severities_db, resolutions_db, status_db, type_db, key_words_db, key_words_num_db)

def autolabel(rects, ax):
    for rect in rects:
        height = rect.get_height()
        ax.annotate('{}'.format(height),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

def plot_non_sec_bugs_results(project, filename, labels, data_1, data_2, label_d_1, label_d_2, 
        field, percentage):
    x = np.arange(len(labels))
    width = 0.4
    fig, ax = plt.subplots()
    rects1 = ax.bar(x - width/2, data_1, width, label=label_d_1)
    rects2 = ax.bar(x + width/2, data_2, width, label=label_d_2)
    ax.set_ylabel('%')
    ax.set_title(project + " - " + field + " (" + str(percentage) + ")")
    ax.set_xticks(x)
    ax.set_xticklabels(labels, rotation='vertical')
    ax.set_ylim([0, 100])
    ax.legend()

    autolabel(rects1, ax)
    autolabel(rects2, ax)

    fig.tight_layout()

    plt.savefig(filename, format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    plt.close(fig)
                        
def count_creators_bugs(collections):
    creators = []
    for coll in collections:
        for bug in coll.find({}):
            if bug['creator'] not in creators:
                creators.append(bug['creator'])

    return len(creators)