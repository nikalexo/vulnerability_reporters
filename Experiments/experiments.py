"""
Experiments on reporters
"""

import matplotlib.pyplot as plt
from matplotlib import rc
from scipy.stats import chisquare
from scipy.stats import chi2_contingency
from scipy import stats
from git import Repo
from pymongo import MongoClient
from fuzzywuzzy import fuzz
import numpy as np
import pandas as pd
import itertools
import time
import json
import csv
import re
import utils

# Investigate reporters distribution
def reporter_distribution(rep2info, prj2cves):
    
    # Get number of cves per reporter - all projects together
    num_list, _ = utils.get_rep_num_cves(rep2info, 'all')
    # Plot distribution
    utils.dist_plot("./results/reporter_distribution/distribution_reporters_all.pdf", num_list)
    # Do power law test - Warning can be safely ignored based on comments by the library's developers
    results_str = utils.power_law_test(num_list, 'All')
    # Store results
    with open("./results/reporter_distribution/power_law_test_all.txt", "w") as f:
        f.write(results_str)

    for project in prj2cves.keys():
        # Get number of cves per reporter for current project
        num_list, _ = utils.get_rep_num_cves(rep2info, prj2cves[project])
        utils.dist_plot("./results/reporter_distribution/distribution_reporters_" + project + ".pdf", num_list)
        results_str = utils.power_law_test(num_list, project)
        with open("./results/reporter_distribution/power_law_test_" + project + ".txt", "w") as f:
            f.write(results_str)
        
# Investigate the number of reporters over time
def number_reporters_over_time(begin, end, prj2cves, cve2reps, cve2year):

    # Generate reporters per year list
    rep2year = dict()

    # We will look into the years 'begin' to 'end'
    n = end - begin + 1
    
    # Create mapping from reporter to year for each project
    for project in prj2cves.keys():
        rep2year[project] = [ [] for i in range(n) ]
    rep2year['total'] = [ [] for i in range(n) ]

    for cve_id in cve2reps:
        year = cve2year[cve_id]
        projs = ['total']
        for project in prj2cves.keys():
            if cve_id in prj2cves[project]:
                projs.append(project)

        reps = cve2reps[cve_id]
        for rep in reps:
            for proj in projs:
                if year-begin > -1:
                    if rep not in rep2year[proj][year-begin]:
                        rep2year[proj][year-begin].append(rep)
    
    # Create mapping from year to number of reporters for each project         
    rep_num_2year = dict()
    for project in prj2cves.keys():
        rep_num_2year[project] = [0] * n
    rep_num_2year['total'] = [0] * n

    for project in rep2year:
        for i in range(len(rep2year[project])):
            rep_num_2year[project][i] = len(rep2year[project][i])

    # Create sequence of the years to look into
    years = range(begin,end+1)
    
    # Plot results of mapping years to number of reporters for each project
    fig= plt.figure(figsize=(6,1.5))
    for item in rep_num_2year:
        if item != 'total':
            plt.plot(years,rep_num_2year[item], label=item)
            plt.ylabel('Reporters')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
    fig.savefig("./results/reporter_dev_over_time/reporters_per_year_" + str(begin) + "_" + str(end) + ".pdf", format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Create mapping from year to number of cves for each project
    cve_proj_2year = dict()
    for project in prj2cves.keys():
        cve_proj_2year[project] = [0] * n

    for cve in cve2year:
        year = cve2year[cve]
        if year-begin > -1:
            for project in prj2cves.keys():
                if cve in prj2cves[project]:
                    cve_proj_2year[project][year-begin] += 1

    # Plot results of mapping years to number of cves for each project
    fig= plt.figure(figsize=(6,1.5))
    for item in rep_num_2year:
        if item != 'total':
            plt.plot(years,cve_proj_2year[item], label=item)
            plt.ylabel('CVEs')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
    fig.savefig("./results/reporter_dev_over_time/cves_per_year_" + str(begin) + "_" + str(end) + ".pdf", format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Now we will look into the reports per reporter
    
    fig= plt.figure(figsize=(6,1.5))
    for item in rep_num_2year:
        per_rep = []
        if item != 'total':
            for i in range(len(rep_num_2year[item])):
                if rep_num_2year[item][i] != 0:
                    per_rep.append(float(cve_proj_2year[item][i])/rep_num_2year[item][i])
                else:
                    per_rep.append(0)
            plt.plot(years, per_rep, label=item)
            plt.ylabel('Avg. reports/reporter')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
            #plt.legend()
    fig.savefig("./results/reporter_dev_over_time/reports_per_rep_per_year_" + str(begin) + "_" + str(end) + ".pdf", format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Now we will look into the reporters per cve
    for item in rep_num_2year:
        per_rep = []
        if item != 'total':
            for i in range(len(rep_num_2year[item])):
                if rep_num_2year[item][i] != 0:
                    per_rep.append(float(rep_num_2year[item][i]/cve_proj_2year[item][i]))
                else:
                    per_rep.append(0)
            plt.plot(years,per_rep, label=item)
            plt.ylabel('Average reporters per cve')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
    plt.savefig("./results/reporter_dev_over_time/reporters_per_cve_per_year_" + str(begin) + "_" + str(end) + ".pdf", format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Then we will look into the new reporters (first time they report)
    new_rep2year = dict()
    for project in prj2cves.keys():
        new_rep2year[project] = [ [] for i in range(n) ]
    new_rep2year['total'] = [ [] for i in range(n) ]

    for cve_id in cve2reps:
        year = cve2year[cve_id]
        projs = ['total']
        for project in prj2cves.keys():
            if cve_id in prj2cves[project]:
                projs.append(project)

        if year-begin > -1:
            reps = cve2reps[cve_id]
            for rep in reps:
                for proj in projs:
                    new = True
                    for i in range(year-begin):
                        if rep in rep2year[proj][i]:
                            new = False
                    if (rep not in new_rep2year[proj][year-begin]) and new:
                        new_rep2year[proj][year-begin].append(rep)

    # Create mapping from year to number of new reporters for each project
    new_rep_num_2year = dict()
    for project in prj2cves.keys():
        new_rep_num_2year[project] = [0] * n
    new_rep_num_2year['total'] = [0] * n

    for project in rep2year:
        for i in range(len(new_rep2year[project])):
            new_rep_num_2year[project][i] = len(new_rep2year[project][i])
    
    # Plot results of mapping years to number of new reporters for each project
    fig= plt.figure(figsize=(6,1.5))
    for item in new_rep_num_2year:
        if item != 'total':
            plt.plot(years,new_rep_num_2year[item], label=item)
            plt.ylabel('New reporters')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
    fig.savefig("./results/reporter_dev_over_time/new_reporters_per_year_" + str(begin) + "_" + str(end) + ".pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Now we will look into the reports per new reporter
    fig= plt.figure(figsize=(6,1.5))
    for item in new_rep_num_2year:
        per_rep = []
        if item != 'total':
            for i in range(len(new_rep_num_2year[item])):
                if new_rep_num_2year[item][i] != 0:
                    per_rep.append(float(cve_proj_2year[item][i])/new_rep_num_2year[item][i])
                else:
                    per_rep.append(0)
            plt.plot(years,per_rep, label=item)
            plt.ylabel('Average reports per new reporter')
            plt.xlabel('Years')
            plt.xticks(np.arange(begin, end+1, step=2))
            plt.legend(loc='upper left')
    fig.savefig("./results/reporter_dev_over_time/reports_per_new_rep_per_year_" + str(begin) + "_" + str(end) + ".pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
# Investigate reports of reporters across projects
def multiple_projects(rep2info, prj2cves):
    
    # Create mapping from reporters to number of reports per project
    rep2proj = dict()
    for rep in rep2info:
        rep2proj[rep] = dict()
        for project in prj2cves.keys():
            rep2proj[rep][project] = 0
        for cve in rep2info[rep]['cves']:
            for project in prj2cves.keys():
                if cve in prj2cves[project]:
                    rep2proj[rep][project] += 1

    
    # Reporters reporting for x projects in field x-1
    mult_rep = [ [] for x in prj2cves.keys() ]

    for rep in rep2proj:
        flag = 0
        for project in prj2cves.keys():
            if rep2proj[rep][project] != 0:
                flag += 1
        if flag > 0:
            mult_rep[flag-1].append(rep)

    results_str = ''

    # Saving results
    for i in range(len(mult_rep)):
        reporters = mult_rep[i]
        results_str += 'Number of reporters with reports for exactly ' + str(i+1) + ' projects: ' + str(len(reporters)) + '\n'
        results_str += 'Reporters: ' + str(reporters) + '\n'
        results_str += 'Number of reporters with reports for at least ' + str(i+1) + ' projects: ' + str(sum(len(x) for x in mult_rep[i:])) + '\n'
        # Note that 'Anonymous might be included in the list
                                
    with open("./results/reporter_across_projects/results.txt", "w") as f:
        f.write(results_str)
        
# Investigate the reporting rate over time
def reporting_rate(begin, end, rep2info, prj2cves, cve2year, top_reps=10):
    
    X = top_reps

    # Plot number of reports of top X reporters per year and each project
    for project in prj2cves.keys():
        utils.plot_top_X(begin, end, project, X, cve2year, rep2info, prj2cves[project])
    
    # Compute stats of reporting rate
    data = dict()
    for project in prj2cves.keys():
        data[project] = utils.compute_stats(begin, end, prj2cves[project], X, rep2info, cve2year)

    # Plot stats of reporting rate for each project
    for project in prj2cves.keys():
        (time_first_last, time_first_peak, time_peak_last) = data[project]
        fig1, ax1 = plt.subplots()
        ax1.set_title(project)
        ax1.boxplot([time_first_last, time_first_peak, time_peak_last])
        plt.xticks([1, 2, 3], ['last-first', 'peak-first', 'last-peak'])
        plt.savefig("./results/reporter_reporting_rate/top_" + str(X) + "_reps_stats_" + project + ".pdf",format="pdf", bbox_inches="tight")
        plt.cla()
        plt.clf()
    
    # Plot everything together in a nice plot
    all_data = [np.random.normal(0, std, size=100) for std in range(len(prj2cves))]
    labels = [x[0].upper() for x in prj2cves.keys()]

    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(7, 4))

    last_first = []
    peak_first = []
    last_peak = []

    for project in prj2cves.keys():
        last_first.append(data[project][0])
        peak_first.append(data[project][1])
        last_peak.append(data[project][2])

    # rectangular box plot
    bplot1 = axes[0].boxplot(last_first,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                             labels=labels, # will be used to label x-ticks
                             whis=[5,95])
    axes[0].set_title('Last-first')

    # notch shape box plot
    bplot2 = axes[1].boxplot(peak_first,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                             labels=labels,  # will be used to label x-ticks
                             whis=[5,95])
    axes[1].set_title('Peak-first')

    bplot3 = axes[2].boxplot(last_peak,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                             labels=labels,  # will be used to label x-ticks
                             whis=[5,95])
    axes[2].set_title('Last-peak')


    # Fill with colors
    #colors = ['pink', 'lightblue', 'lightgreen']
    #for bplot in (bplot1, bplot2):
    #    for patch, color in zip(bplot['boxes'], colors):
    #        patch.set_facecolor(color)

    # adding horizontal grid lines
    for ax in axes:
        ax.yaxis.grid(True)

    axes[0].set_ylabel('Years')

    plt.savefig("./results/reporter_reporting_rate/top_" + str(X) + "_reps_stats_compressed.pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
# Investigate the correlation of reporters and type of vulnerabilties they reported
def reps_and_their_vulnerability_types(rep2info, prj2cves, cve2reps, all_cves, collection):
    
    # Create mapping from cve to category
    cve2cat = dict()
    # Create mapping from cve to cwe
    cve2cwe = dict()

    for cve in all_cves:
        try:
            cwe = collection.find_one({"id": cve})['cwe']
        except:
            # print('CWE for CVE ', cve, 'not found')
            cwe = 'CWE-noinfo'

        cve2cwe[cve] = cwe

        cat = utils.manual_cve_mappings(cwe)
        cve2cat[cve] = cat
    
    # Create mapping from reporter to categories
    rep2cats = dict()
    # Create mapping from reporter to cwes
    rep2cwes = dict()

    for rep in rep2info:
        rep2cats[rep] = [0]*7
        rep2cwes[rep] = dict()

        for cve in rep2info[rep]['cves']:
            cwe = cve2cwe[cve]
            if cwe not in rep2cwes[rep]:
                rep2cwes[rep][cwe] = 1
            else:
                rep2cwes[rep][cwe] += 1

            if cve not in cve2cat or cve2cat[cve] is None:
                # print(cve, ' does not have a type')
                pass
            else:
                rep2cats[rep][cve2cat[cve]] += 1
    
    # Check distribution of CWE number, dominant CWEs
    cwenum = []
    catnum = []
    cwenum_normal = []
    catnum_normal = []

    for rep in rep2cwes:
        temp_cat = 0
        if len(rep2info[rep]['cves']) > 20:
            cwenum.append(len(rep2cwes[rep]))
            # Find max cwe
            max_cwe = 0
            for cwe in rep2cwes[rep]:
                if rep2cwes[rep][cwe] > max_cwe:
                    max_cwe = rep2cwes[rep][cwe]
            
            cwenum_normal.append(max_cwe/len(rep2info[rep]['cves']))
            for cat in rep2cats[rep]:
                if cat != 0:
                    temp_cat += 1
            catnum.append(temp_cat)
            
            # Find max cat
            max_cat = 0
            for cat in rep2cats[rep]:
                if cat > max_cat:
                    max_cat = cat
           
            catnum_normal.append(max_cat/len(rep2info[rep]['cves']))

    # Plot results
    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(7, 4))

    # rectangular box plot
    bplot1 = axes[0].boxplot(cwenum,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                              # will be used to label x-ticks
                             whis=[5,95])
    axes[0].set_title('CWEs per reporter')

    bplot2 = axes[1].boxplot(catnum,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                               # will be used to label x-ticks
                             whis=[5,95])
    axes[1].set_title('cats per reporter')

    bplot3 = axes[2].boxplot(cwenum_normal,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                               # will be used to label x-ticks
                             whis=[5,95])
    axes[2].set_title('CWEs most')

    bplot4 = axes[3].boxplot(catnum_normal,
                             vert=True,  # vertical box alignment
                             patch_artist=True,  # fill with color
                               # will be used to label x-ticks
                             whis=[5,95])
    axes[3].set_title('cats most')

    # fill with colors
    #colors = ['pink', 'lightblue', 'lightgreen']
    #for bplot in (bplot1, bplot2):
    #    for patch, color in zip(bplot['boxes'], colors):
    #        patch.set_facecolor(color)

    # adding horizontal grid lines
    for ax in axes:
        ax.yaxis.grid(True)

    axes[0].set_ylabel('Num')

    fig.tight_layout() # Or equivalently,  "plt.tight_layout()"
    plt.savefig("./results/reporters_type_vulnerabilities/cwes_and_cats_per_reps.pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
    
    # Check if a reporter is focused (50% or 66% same cwe/category) per project normalized
    i = 0

    for project, cves in prj2cves.items():
        total_dist = [0] * 7
        for cve in cves:
            if cve2cat[cve] is not None:
                total_dist[cve2cat[cve]] += 1

        for j in range(len(total_dist)):
            x = total_dist[j]
            if x==0:
                total_dist[j] = 1
        print(project)
        print(total_dist)
        norm_total_dist = [(x/sum(total_dist)) * 100 for x in total_dist]

        has_seen = []

        for rep in rep2info:
            rep2cats[rep] = [0]*7
            rep2cwes[rep] = dict()

            for cve in rep2info[rep]['cves']:
                if cve not in cves:
                    continue
                cwe = cve2cwe[cve]
                if cwe not in rep2cwes[rep]:
                    rep2cwes[rep][cwe] = 1
                else:
                    rep2cwes[rep][cwe] += 1

                if cve not in cve2cat or cve2cat[cve] is None:
                    # print(cve, ' does not have a type')
                    pass
                else:
                    rep2cats[rep][cve2cat[cve]] += 1
        
        
        i += 1
        
        num_reps = 0
        num_reps_div = 0
        num_reps_foc = 0
        
        
        for cve in cves:
            for rep in cve2reps[cve]:
                if rep not in has_seen:
                    has_seen.append(rep)
                    if rep in rep2cats:
                        cats = rep2cats[rep]
                        total_cat = sum(cats)
                        if total_cat < 20:
                            continue
                        num_reps += 1
                        norm_cats = [((x/total_cat) * 100) for x in cats]
                        #print(cats[1:], total_dist[1:])
                        #print(chisquare(norm_cats[1:], f_exp=norm_total_dist[1:]))

                        expected_cats = [x/sum(total_dist)*total_cat for x in total_dist]

                        #print(cats, expected_cats)
                        (chi2, p1) = chisquare(cats[1:], f_exp=expected_cats[1:])
                        obs = np.array([cats, total_dist])
                        (chi2, p2, dof, ex) = chi2_contingency(obs)


                        max_cat = max(norm_cats)
                        if p1<0.05:
                            print(cats, expected_cats)
                            num_reps_div += 1
                        if 2*max_cat > sum(norm_cats) and p1<0.05:
                            #print(chisquare(norm_cats[1:], f_exp=norm_total_dist[1:]))
                            print(rep, cats, norm_cats.index(max_cat), p1, p2)
                            print(cats, expected_cats)
                            num_reps_foc += 1
                            
        print(project,num_reps, num_reps_div, num_reps_foc)

    # print(chi2_contingency([[12,32,20], [40,80,40]]))
    
    # We want to do this for each project individually
    for project, cves in prj2cves.items():
        cwe_dist = dict()
        cat_dist = dict()
        # print(projects[i], len(p))

        for cve in cves:
            cwe = cve2cwe[cve]
            cat = cve2cat[cve]
            if cwe not in cwe_dist:
                cwe_dist[cwe] = 1
            else:
                cwe_dist[cwe] += 1

            if str(cat) not in cat_dist:
                cat_dist[str(cat)] = 1
            else:
                cat_dist[str(cat)] += 1

        sorted_cwe = {k: v for k, v in sorted(cwe_dist.items(), key=lambda item: item[1], reverse = True)[:5]}

        # Plot results
        plt.bar(sorted_cwe.keys(), sorted_cwe.values(), color='g')
        plt.savefig("./results/reporters_type_vulnerabilities/results_" + project + "_1.pdf",format="pdf", bbox_inches="tight")
        plt.cla()
        plt.clf()
        plt.bar(cat_dist.keys(), cat_dist.values(), color='g')
        plt.savefig("./results/reporters_type_vulnerabilities/results_" + project + "_2.pdf",format="pdf", bbox_inches="tight")
        plt.cla()
        plt.clf()
        
# Investigate bug bounty rewards of reporters
def bug_bounties(prj2cves, cve2reps, all_cves, path_cve2bounty):

    # Load mapping from cves to number of bounties
    cve2bounty = dict()
    with open(path_cve2bounty, 'r') as f:
        cve2bounty = json.load(f)
        
    results_str = ''

    # Find number of cves per project
    for project in prj2cves:
        i = 0
        for cve in prj2cves[project]:
            if cve in cve2bounty:
                i += 1
        percentage = '%.2f' % (float(i) / len(prj2cves[project]) * 100)
        results_str += 'For ' + project + ': Number of bounty-awarded bugs: ' + str(i) + ' / ' + str(len(prj2cves[project])) + ' = ' + str(percentage) + ' %\n'
    
    results_str += '\n'

    # Create mapping from reporters to number of bounties
    rep2bounty = dict()
    for cve in cve2bounty:
        reps = cve2reps[cve]
        if len(reps) != 1:
            continue
        elif reps[0] in rep2bounty:
            rep2bounty[reps[0]] += 1
        else:
            rep2bounty[reps[0]] = 1

    # Create mapping from project to number of bounties
    prj2bounty = dict()
    for project in prj2cves.keys():
        prj2bounty[project] = 0

    # Total number of cves where a reporter was rewarded with a bounty 
    total_bounty_cves = 0

    for cve in all_cves:
        flag = False
        for rep in cve2reps[cve]:
            if rep in rep2bounty:
                flag = True

        if flag:
            total_bounty_cves += 1
            for project in prj2cves.keys():
                if cve in prj2cves[project]:
                    prj2bounty[project] += 1

    # Number of cves with a given reporter
    with_rep = 0
    for cve in cve2reps:
        if cve2reps[cve] != []:
            with_rep += 1

    results_str += 'CVEs with reporters associated to bounties / CVEs with a given reporter: ' + str(total_bounty_cves) + ' / ' + str(with_rep) + '\n\n'

    for project in prj2cves:
        i = 0
        for cve in prj2cves[project]:
            for rep in cve2reps[cve]:
                if rep in rep2bounty:
                    i += 1
                    break
        percentage = '%.2f' % (float(i) / len(prj2cves[project]) * 100)
        results_str += 'For ' + project + ': Number of bounty-related cves with a reporter rewarded with a bounty in general / all CVEs of this project: ' + str(i) + '/' + str(len(prj2cves[project])) + ' = ' + str(percentage) + '%\n'                                

    with open("./results/reporters_bug_bounties/results.txt", "w") as f:
        f.write(results_str)
        
# Investigate socal media professional networking profiles of reporters w.r.t. security-related stuff
def social_media_sec_rel(rep2info, path_rep2profiles):

    # Create mapping from reporters to number of reported cves
    rep2num = dict()
    project = 'all'
    for rep in rep2info:
        templist = []
        for cve in rep2info[rep]['cves']:
            if project == 'all' or cve in project:
                templist.append(cve)
            if len(templist) > 0:
                rep2num[rep] = len(templist)

    # Sort rep2num in descending order w.r.t. nummber of cves
    sorted_rep2num = {k: v for k, v in sorted(rep2num.items(), key=lambda item: item[1], reverse = True)}
    
    # Load mapping from reporters to Linkedin profiles
    rep2profiles = dict()
    with open(path_rep2profiles, 'r') as fp:
        rep2profiles = json.load(fp)

    # Store all reporters and and reporters being people in separate lists 
    all_reps = []
    only_people = []
    for rep in sorted_rep2num:
        all_reps.append(rep)
        if rep2info[rep]['type'] == ['p']:
            only_people.append(rep)

    i = 0
    limit = len(rep2info)

    relevant_cats = ['summary','industryName', 'headline', 'experience', 'skills', 'education']
    j = 0

    exceptions = []

    for rep in only_people[:limit]:
        if rep in rep2profiles:
            if rep2profiles[rep] == []:
                del(rep2profiles[rep])
                continue
            i += 1
            try:
                industry = rep2profiles[rep]['industryName']
            except:
                if isinstance(rep2profiles[rep], list) and len(rep2profiles[rep]) > 0:
                    repdict = rep2profiles[rep][0]
                    rep2profiles[rep] = repdict
                    if 'industryName' in repdict:
                        industry = repdict['industryName']
                        continue

                industry = None
                continue

            sec_industries = ['Computer & Network Security', 'Information Technology & Services', 'Computer Software', 'Internet', 'Computer Networking', 'Telecommunications', 'Computer Hardware', 'Research']
            sec_skills = ['Computer Security', 'Web Application Security', 'Mobile Automation Testing']

            if industry not in sec_industries:
                j += 1
                if True:
                    flag_compsec = False
                    flag_physec = False
                    for skill in rep2profiles[rep]['skills']:
                        if skill['name'] in sec_skills:
                            flag_compsec = True
                        if skill['name'] == 'Physical Security':
                            flag_physec = True

                    if not flag_compsec or flag_physec:
                        exceptions.append(rep)

    results_str = 'Found information for: ' + str(i) + ' out of ' + str(limit) + ' most productive reporters\n'
    results_str += 'Found ' + str(len(exceptions)) + ' exceptions from the above\n'

    for rep in exceptions:
        del(rep2profiles[rep])
        
    repnames = [rep for rep in rep2profiles]

    for rep in repnames:
        if rep2profiles[rep] == []:
            del(rep2profiles[rep])
    
    with open("./results/reporters_social_media_sec_related/results.txt", "w") as f:
        f.write(results_str)
    
    return rep2profiles

# Investigate if reporters mention vulnerability discoveries in their online professional networking profile
def social_media_reputation(rep2info, search_re, path_rep2profiles):

    # Load mapping from reporters to Linkedin profiles
    rep2profiles = dict()
    with open(path_rep2profiles, 'r') as fp:
        rep2profiles = json.load(fp)
    
    # Create mapping from expressions to search to reporters fulfilling them in their profile
    expr2reps = dict()
    for expr in search_re:
        expr2reps[str(expr)] = []

    for rep in rep2profiles:
        for expr in search_re:
            found = False

            try:
                summary = rep2profiles[rep]['summary']
            except:
                summary = ''
            try:
                headline = rep2profiles[rep]['headline']
            except:
                headline = ''

            if re.search(expr, summary) is not None:
                found = True

            if re.search(expr, headline) is not None:
                found = True


            try:
                for exp in rep2profiles[rep]['experience']:
                    desc = exp['description']
                    if re.search(expr, desc) is not None:
                        found = True
            except:
                pass

            if found:
                expr2reps[str(expr)].append(rep)

    # Create string to save results
    results_str = "Reporters with a profile: " + str(len(rep2profiles)) + "\n\n"

    # Get all possible combinations of the expressions
    expr_tuples = []
    for x in range(len(expr2reps.keys()) + 1): # all possible length
        tuples = list(itertools.combinations(list(expr2reps.keys()), x))
        expr_tuples.append(tuples)
    
    # Get number of reporter's profiles including a given special combination
    for tuples in expr_tuples:
        for tuple_ in tuples:
            reps = []
            for rep in rep2profiles:
                found = True
                for expr in tuple_:
                    if rep not in expr2reps[expr]:
                        found = False
                if found:
                    reps.append(rep)
            # Write result of current tuple
            results_str += "Reporters fulfilling expressions '" + str(tuple_) + "': " + str(len(reps))
            results_str += ", Percentage: " + str("%.0f" % (len(reps)/len(rep2profiles)*100)) +  ' %\n'

    # Create mapping from reporters to number of reported cves
    rep2num = dict()
    project = 'all'
    for rep in rep2info:
        templist = []
        for cve in rep2info[rep]['cves']:
            if project == 'all' or cve in project:
                templist.append(cve)
            if len(templist) > 0:
                rep2num[rep] = len(templist)

    # Sort rep2num in descending order w.r.t. nummber of cves
    sorted_rep2num = {k: v for k, v in sorted(rep2num.items(), key=lambda item: item[1], reverse = True)}

    # Get reporters being people in separate lists 
    only_people = []
    for rep in sorted_rep2num:
        if rep2info[rep]['type'] == ['p']:
            only_people.append(rep)

    count = 0
    for rep in only_people[:100]:
        if rep in rep2profiles:
            count += 1
    results_str += "\n"
    results_str += str(count) + '/ 100 top reporter found with a profile\n'
    
    with open("./results/reporters_social_media_reputation/results.txt", "w") as f:
        f.write(results_str)
        
# Investigate how many reporters come from the corresponding organisations of projects affected by the their reported cves
def reporters_employed(rep2info, prj2cves, cve2reps, all_cves, path_rep2profiles, path_cve2bounty):

    # First look into LinkedIn with time, then without considering time and then in affs
    
    # Load mapping from reporters to Linkedin profiles
    rep2profiles = dict()
    with open(path_rep2profiles, 'r') as fp:
        rep2profiles = json.load(fp)

    print('Profiles from Linkedin: ', len(rep2profiles))
    
    # Create mapping from cves to affiliation by taking a look into LinkedIn profiles and into rep2info
    cve2affs = dict()

    for cve in all_cves:
        cve2affs[cve] = []

    for cve in cve2reps:
        cve_year = int(cve[4:8])
        temp_affs = []

        for rep in cve2reps[cve]:
            found_aff = False
            if rep in rep2profiles:
                for job in rep2profiles[rep]['experience']:
                    try:
                        cname = job['companyName']

                        # For Mozilla
                        if re.match(r'.*mozilla.*', cname, re.IGNORECASE):
                            if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                                found_aff = True
                                cve2affs[cve].append('Mozilla')
                        # For Google
                        if re.match(r'.*google.*', cname, re.IGNORECASE):
                            if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                                found_aff = True
                                cve2affs[cve].append('Google')
                        # For Apache
                        if re.match(r'.*apache.*', cname, re.IGNORECASE):
                            if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                                found_aff = True
                                cve2affs[cve].append('Apache')
                        # For PHP
                        if re.match(r'.*php.*', cname, re.IGNORECASE):
                            if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                                found_aff = True
                                cve2affs[cve].append('PHP')
                        # For Linux
                        if re.match(r'(.*linux.*)', cname, re.IGNORECASE):
                            if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                                found_aff = True
                                cve2affs[cve].append('Linux')

                        # For other companies
                        if job['timePeriod']['startDate']['year'] <= cve_year and 'endDate' in job['timePeriod'] and job['timePeriod']['endDate']['year'] >= cve_year:
                            found_aff = True
                            cve2affs[cve].append(cname)
                    except KeyError:
                        pass

            if found_aff:
                continue

            if rep2info[rep]['type'] != ['p']:
                if re.match(r'(.*mozilla.*)',rep,re.IGNORECASE):
                    found_aff = True
                    cve2affs[cve].append('Mozilla')
                elif re.match(r'.*google.*', rep, re.IGNORECASE):
                    found_aff = True
                    cve2affs[cve].append('Google')
                elif re.match(r'.*android.*', rep, re.IGNORECASE):
                    cve2affs[cve].append('Android')
                elif re.match(r'.*apache.*', rep, re.IGNORECASE):
                    found_aff = True
                    cve2affs[cve].append('Apache')
                elif re.match(r'.*php.*', rep, re.IGNORECASE):
                    found_aff = True
                    cve2affs[cve].append('PHP')
                elif re.match(r'(.*linux.*)', rep, re.IGNORECASE):
                    found_aff = True
                    cve2affs[cve].append('Linux')
                else:
                    found_aff = True
                    cve2affs[cve].append(rep)

            if found_aff:
                continue

            for aff in rep2info[rep]['affs']:
                if re.match(r'(.*mozilla.*)',aff,re.IGNORECASE):
                    cve2affs[cve].append('Mozilla')
                elif re.match(r'(.*google.*)|(.*project zero.*)', aff, re.IGNORECASE):    
                    cve2affs[cve].append('Google')
                elif re.match(r'.*apache.*', aff, re.IGNORECASE):
                    cve2affs[cve].append('Apache')
                elif re.match(r'.*php.*', aff, re.IGNORECASE):
                    cve2affs[cve].append('PHP')
                elif re.match(r'(.*linux.*)', aff, re.IGNORECASE):
                    cve2affs[cve].append('Linux')
                else:
                    cve2affs[cve].append(aff)

    j = 0
    for cve in cve2affs:
        if cve2affs[cve] != []:
            j += 1

    results_str = 'Found affiliations for ' + str(j) + ' out of ' + str(len(all_cves)) + ' CVEs (uncleaned) \n\n'
    
    # Now clean affiliations

    # Create mapping from affiliations to cves
    aff2cves = dict()

    for cve in cve2affs:
        for aff in cve2affs[cve]:
            if aff not in aff2cves:
                aff2cves[aff] = [cve]
            else:
                if cve not in aff2cves[aff]:
                    aff2cves[aff].append(cve)

    # Sort affiliations by number of cves
    top_affs = {k: v for k, v in sorted(aff2cves.items(), key=lambda item: len(item[1]), reverse = True)}

    # Now merge similar names
    similar_names = []
    for aff1 in top_affs:
        for aff2 in top_affs:
            if aff1 != aff2 and (aff1.lower() == aff2.lower() or (len(aff1) > 5 and len(aff2) > 5 and fuzz.ratio(aff1, aff2) > 90)):
                similar_names.append((aff1,aff2))

    similar_names_sets = []
    for (aff1,aff2) in similar_names:
        found_set = False
        for s in similar_names_sets:
            if aff1 in s and aff2 not in s:
                s.append(aff2)
                found_set = True
            elif aff1 not in s and aff2 in s:
                s.append(aff1)
                found_set = True
            elif aff1 in s and aff2 in s:
                found_set = True
        if not found_set:
            similar_names_sets.append([aff1, aff2])

    for aff_set in similar_names_sets:
        utils.merge_affs(aff_set, top_affs)

    # Now some manual cleaning
    del top_affs['these issues']
    #del top_affs['this issue']
    #del top_affs['these vulnerabilities']
    
    # Now some manual merging
    manual_merge = [['Google', 'Google Inc', 'Chrome Security'],
                    ['Tencent', 'team509', 'team509; Microsoft Vulnerabilit', 'Tencent\'s Xuan', 'Tencent\'s Xuanwu Lab'],
                    ['SecurityReason', 'SecurityReason Research'],
                    ['Qihoo 360 Technology Co. Ltd', 'C0RE Team', 'IceSword Lab', 'IceSword Lab & Hao Chen', 'Alpha Team'
                    ,'Alpha Team from Qihoo 360 Technology Co. Ltd', '奇虎360'],
                    ['Mozilla', 'Mozilla Japan', 'Mozilla Corporation'],
                    ['Red Hat', 'Red Hat Engineering'],
                    ['Trend Micro Zero Day Initiative', 'via TippingPoint\'s Zero Day Initiative',
                     'the Zero Day Initiative', 'TippingPoint'],
                    ['IBM', 'IBM Internet Security Systems'],
                    ['Apache', 'the ASF']]

    for aff_set in manual_merge:
        utils.merge_affs(aff_set, top_affs)

    top_affs = {k: v for k, v in sorted(top_affs.items(), key=lambda item: len(item[1]), reverse = True)}
    
    
    raw_data = dict()
    raw_data['internal'] = []
    raw_data['bounty_other'] = []
    raw_data['bounty_unknown'] = []
    raw_data['other'] = []
    raw_data['unknown'] = []

    # Load mapping from cves to number of bounties
    cve2bounty = dict()
    with open(path_cve2bounty, 'r') as f:
        cve2bounty = json.load(f)

    i = 0

    for project in prj2cves:
        bounties = []
        temp_top_affs = dict()
        temp_top_affs['bounty'] = []
        for aff in top_affs:
            temp_top_affs[aff] = []
            for cve in top_affs[aff]:
                if cve in prj2cves[project]:
                    if cve in cve2bounty and ((project == "mozilla" and aff == 'Mozilla') or (project == "linux" and aff == 'Linux')
                                             or (project == "apache" and aff == 'Apache') or (project == "php" and aff == 'PHP')):
                        bounties.append(cve)
                        temp_top_affs['bounty'].append(cve)
                    else:
                        temp_top_affs[aff].append(cve)

        temp_top_affs = {k: v for k, v in sorted(temp_top_affs.items(), key=lambda item: len(item[1]), reverse = True)}

        cves_with_aff = []
        total_with_doubles = 0
        for aff in temp_top_affs:
            for cve in temp_top_affs[aff]:
                total_with_doubles += 1
                if cve not in cves_with_aff:
                    cves_with_aff.append(cve)

        in_aff_list = ['Mozilla', 'Linux', 'Apache', 'PHP']
        internal = 0
        bounty_other = 0
        bounty_unknown = 0
        other = 0
        unknown = 0
        for cve in prj2cves[project]:
            if cve in temp_top_affs[in_aff_list[i]] and cve not in cve2bounty:
                internal += 1
            elif cve in cves_with_aff:
                other += 1
                if cve in cve2bounty:
                    bounty_other += 1
            else:
                unknown += 1
                if cve in cve2bounty:
                    bounty_unknown += 1

        i += 1

        results_str += 'Project: ' + project + '\n'
        results_str += 'Total CVEs: ' + str(len(prj2cves[project])) + '\n'
        results_str += 'With aff: ' + str(len(cves_with_aff)) + '\n'
        results_str += 'Internal: ' + str(internal) + '\n'
        results_str += 'bounty from other orgs: ' + str(bounty_other) + '\n'
        results_str += 'bounty from unknown: ' + str(bounty_unknown) + '\n'
        results_str += 'External: ' + str(other) + '\n'
        results_str += 'Unknown: ' + str(unknown) + '\n'
        results_str += 'Total with doubles: ' + str(total_with_doubles) + '\n\n'

        raw_data['internal'].append(internal)
        raw_data['other'].append(other - bounty_other)
        raw_data['bounty_other'].append(bounty_other)
        raw_data['unknown'].append(unknown - bounty_unknown)
        raw_data['bounty_unknown'].append(bounty_unknown)
     
    with open("./results/reporters_employed/results.txt", "w") as f:
        f.write(results_str)

    # Data
    r = [0,1,2,3]
    df = pd.DataFrame(raw_data)

    # From raw value to percentage
    totals = [i+j+k+l+m for i,j,k,l,m in zip(df['internal'], df['other'],  df['bounty_other'], df['unknown'], df['bounty_unknown'])]
    internal = [i / j * 100 for i,j in zip(df['internal'], totals)]
    other = [i / j * 100 for i,j in zip(df['other'], totals)]
    bounty_other = [i / j * 100 for i,j in zip(df['bounty_other'], totals)]
    unknown = [i / j * 100 for i,j in zip(df['unknown'], totals)]
    bounty_unknown = [i / j * 100 for i,j in zip(df['bounty_unknown'], totals)]

    #print(internal, other, bounty_other, bounty_unknown, unknown)    
    
    # Plot results
    barWidth = 0.45
    names = list(prj2cves.keys())

    plt.figure(num=None, figsize=(4, 2.5), dpi=80, facecolor='w', edgecolor='k')

    # Create green Bars
    plt.bar(r, internal, color='#f0f9e8', edgecolor='black', width=barWidth, label="Internal")
    # Create orange Bars
    plt.bar(r, other, bottom=internal, color='#bae4bc', edgecolor='black', width=barWidth, label="Other")
    # Create blue Bars
    plt.bar(r, bounty_other, bottom=[i+j for i,j in zip(internal, other)], color='#7bccc4', edgecolor='black', width=barWidth, label="Other $")
    # Create blue Bars
    plt.bar(r, bounty_unknown, bottom=[i+j+w for i,j,w in zip(internal, other, bounty_other)], color='#43a2ca', edgecolor='black', width=barWidth, label="Unknown $")
    # Create blue Bars
    plt.bar(r, unknown, bottom=[i+j+w+y for i,j,w,y in zip(internal, other, bounty_other, bounty_unknown)], color='#0868ac', edgecolor='black', width=barWidth, label="Unknown")

    # Custom x axis
    plt.xticks(r, names)
    plt.xlabel("project")

    # Add a legend
    plt.legend(loc='upper left', bbox_to_anchor=(1,1),  ncol=1)
    plt.tight_layout()
    # Save graphic
    plt.savefig("./results/reporters_employed/organizations.pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()

# Investigate if and how many vulnerability reporters are commmiters
def reporters_commiters(rep2info, prj2cves, path_rep2commits):

    rep2commits = dict()
    for path in path_rep2commits:
        with open(path) as jf:
            rep2commits_project = json.load(jf)
        
        for rep in rep2commits_project:
            if rep not in rep2commits:
                rep2commits[rep] = 0
            rep2commits[rep] += len(rep2commits_project[rep])
    
    # See how many reporters have made at least 1 commit
    people = 0
    i = 0
    for rep in rep2info:
        if rep2info[rep]['type'] != ['p']:
            continue
        people += 1
        if rep not in rep2commits:
            continue
        if rep2commits[rep] > 100:
            i += 1

    results_str = 'Found commit(s) for ' + str(i) + ' out of ' + str(people) + ' reporters\n'
    
    with open("./results/reporters_commiters/results.txt", "w") as f:
        f.write(results_str)

# Investigate non-security bugs of vulnerability reporters compared to the rest
def bugs_reporters(projects, project2cves, collections, rep_collection, rep2cves_files, rep2non_cve_bugs_files, rep2cve_bugs_files, bug2commits_files, key_words, top_percentage):
    
    # Find field names and possible values in bugs 
    (severities_standard, resolutions_standard, status_standard, type_standard) = utils.fill_standards(projects, collections)

    # Check bugs of reporters (100 % of reps)
    (bugs_of_reps, severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep) = utils.check_reporters(1, projects, severities_standard, 
            resolutions_standard, status_standard, type_standard, key_words, rep2cves_files, rep2non_cve_bugs_files, collections)
    
    # Check bugs not created by reporters
    (bugs_in_db, severities_db, resolutions_db, status_db, type_db, key_words_db, key_words_num_db) = utils.check_rest(bugs_of_reps, projects, severities_standard, 
            resolutions_standard, status_standard, type_standard, key_words, collections)
    
    # Store results
    utils.store_results_bugs_reporters(projects, bugs_of_reps, 
            severities_standard, resolutions_standard, status_standard, type_standard, key_words,
            severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep, 
            bugs_in_db, severities_db, resolutions_db, status_db, type_db, key_words_db, key_words_num_db, 
            1, "results/reporters_non_security_bugs")
    
    # Check bugs of reporters (_ % of reps)
    for i in range(len(top_percentage)):
        percentage = top_percentage[i]

        (bugs_of_reps, severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep) = utils.check_reporters(percentage, projects, severities_standard, 
            resolutions_standard, status_standard, type_standard, key_words, rep2cves_files, rep2non_cve_bugs_files, collections)

        utils.store_results_bugs_reporters(projects, bugs_of_reps, 
                severities_standard, resolutions_standard, status_standard, type_standard, key_words,
                severities_reps, resolutions_reps, status_reps, type_reps, key_words_rep, key_words_num_rep,
                bugs_in_db, severities_db, resolutions_db, status_db, type_db, key_words_db, key_words_num_db, 
                percentage, "results/reporters_non_security_bugs")
    
    # Chi-square and Mann-Whitney tests for all projects and all bug fields + plotting
    
    # Create tables for results
    title = ["Category"]
    title.extend(projects)
    table_u = [title.copy()]
    table_c = [title.copy()]
    table_pu = [title.copy()]
    table_pc = [title.copy()]

    for field in ["severity", "resolution", "status", "type", "keywords"]:
        row = [field]
        row.extend(["-" for x in range(len(projects))])
        table_u.append(row.copy())
        table_c.append(row.copy())
        table_pu.append(row.copy())
        table_pc.append(row.copy())

    top_percentage.append(1)
    # Add severity results
    for percentage in top_percentage:
        rows = []
        with open("./results/reporters_non_security_bugs/statistics_severity_" + str(percentage) + ".csv", "r") as f:
            reader = csv.reader(f)
            for row in reader:
                rows.append(row)
        for p in range(len(projects)):
            if projects[p] != "PHP":
                row_1 = rows[p*2]
                row_2 = rows[p*2+1]
                labels = [w.split("-")[0] for w in row_1[1:int(((len(row_1)-1)/2)+1)]]
                labels = list(dict.fromkeys(labels))
                data_1 = row_2[1:1+len(labels)]
                data_2 = row_2[1+len(labels):1+len(labels)+len(labels)]
                data_1 = [int(x) for x in data_1]
                data_2 = [int(x) for x in data_2]
                sum_1 = sum(data_1)
                sum_2 = sum(data_2)
                q = sum_2 / sum_1
                data_1_2 = [x for x in data_1]
                data_2_2 = [int(x/q) for x in data_2]
                
                # remove classes with value < 5
                to_remove = []
                for i in range(len(data_1_2)):
                    if data_1_2[i] < 5:
                        to_remove.append(i)
                for r in reversed(to_remove):
                    data_1_2.pop(r)
                    data_2_2.pop(r)

                # Statistical tests

                # null hypothesis: data_2_1 the rest bugs
                #print(projects[p], percentage)
                (chisq, pp) = stats.chisquare(data_1_2, data_2_2)
                table_c[1][p+1] = chisq
                table_pc[1][p+1] = pp
                #print("chi-square:", chisq, ", p-value:", pp)
                (statistic, pp) = stats.mannwhitneyu(data_1, data_2)
                table_u[1][p+1] = statistic
                table_pu[1][p+1] = pp
                #print("mann-whitney u:", statistic, ", p-value:", pp)

                data_1_1 = [int(x/sum_1*100+0.5) for x in data_1]
                data_2_1 = [int(x/sum_2*100+0.5) for x in data_2]

                # Plots
                filename = "./results/reporters_non_security_bugs/plot_severity_" + projects[p] + "_" + str(percentage) + ".png"
                utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                    "Reporter Bugs", "Rest Bugs", "Severity", percentage)

                # Plot distribution of categories between reporters and rest
                if projects[p] == "Apache" or projects[p] == "Mozilla" or projects[p] == "Firefox" or projects[p] == "Thunderbird":
                    # position of major and critical
                    major_index = labels.index("major")
                    critical_index = labels.index("critical")
                    labels.append("major + critical")
                    data_1.append(data_1[major_index] + data_1[critical_index])
                    data_2.append(data_2[major_index] + data_2[critical_index])

                sum_data_x = [data_1[x] + data_2[x] for x in range(len(data_1))]
                data_1_1 = [int(data_1[x]/sum_data_x[x]*100+0.5) for x in range(len(data_1))]
                data_2_1 = [int(data_2[x]/sum_data_x[x]*100+0.5) for x in range(len(data_1))]

                filename = "./results/reporters_non_security_bugs/plot_severity_field_focussed_" + projects[p] + "_" + str(percentage) + ".png"
                utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                    "Reporter Bugs", "Rest Bugs", "Severity", percentage)

    # Add resolution results
    for percentage in top_percentage:
        rows = []
        with open("./results/reporters_non_security_bugs/statistics_resolution_" + str(percentage) + ".csv", "r") as f:
            reader = csv.reader(f)
            for row in reader:
                rows.append(row)
        for p in range(len(projects)):
            if projects[p] != "PHP":
                row_1 = rows[p*2]
                row_2 = rows[p*2+1]
                labels = [w.split("-")[0] for w in row_1[1:int(((len(row_1)-1)/2)+1)]]
                labels = list(dict.fromkeys(labels))
                data_1 = row_2[1:1+len(labels)]
                data_2 = row_2[1+len(labels):1+len(labels)+len(labels)]
                data_1 = [int(x) for x in data_1]
                data_2 = [int(x) for x in data_2]
                sum_1 = sum(data_1)
                sum_2 = sum(data_2)
                q = sum_2 / sum_1
                data_1_2 = [x for x in data_1]
                data_2_2 = [int(x/q) for x in data_2]

                # remove classes with value < 5
                to_remove = []
                for i in range(len(data_1_2)):
                    if data_1_2[i] < 5:
                        to_remove.append(i)
                for r in reversed(to_remove):
                    data_1_2.pop(r)
                    data_2_2.pop(r)

                # Statistical tests

                # null hypothesis: data_2_1 the rest bugs
                #print(projects[p], percentage)
                (chisq, pp) = stats.chisquare(data_1_2, data_2_2)
                table_c[2][p+1] = chisq
                table_pc[2][p+1] = pp
                #print("chi-square:", chisq, ", p-value:", pp)
                (statistic, pp) = stats.mannwhitneyu(data_1, data_2)
                table_u[2][p+1] = statistic
                table_pu[2][p+1] = pp
                #print("mann-whitney u:", statistic, ", p-value:", pp)

                data_1_1 = [int(x/sum_1*100+0.5) for x in data_1]
                data_2_1 = [int(x/sum_2*100+0.5) for x in data_2]

                # Plots
                filename = "./results/reporters_non_security_bugs/plot_resolution_" + projects[p] + "_" + str(percentage) + ".png"
                utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                    "Reporter Bugs", "Rest Bugs", "Resolution", percentage)

                sum_data_x = [data_1[x] + data_2[x] for x in range(len(data_1))]
                data_1_1 = [int(data_1[x]/sum_data_x[x]*100+0.5) for x in range(len(data_1))]
                data_2_1 = [int(data_2[x]/sum_data_x[x]*100+0.5) for x in range(len(data_1))]

                filename = "./results/reporters_non_security_bugs/plot_resolution_field_focussed_" + projects[p] + "_" + str(percentage) + ".png"
                utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                    "Reporter Bugs", "Rest Bugs", "Resolution", percentage)

    # Add status results
    for percentage in top_percentage:
        rows = []
        with open("./results/reporters_non_security_bugs/statistics_status_" + str(percentage) + ".csv", "r") as f:
            reader = csv.reader(f)
            for row in reader:
                rows.append(row)
        for p in range(len(projects)):
            row_1 = rows[p*2]
            row_2 = rows[p*2+1]
            labels = [w.split("-")[0] for w in row_1[1:int(((len(row_1)-1)/2)+1)]]
            labels = list(dict.fromkeys(labels))
            data_1 = row_2[1:1+len(labels)]
            data_2 = row_2[1+len(labels):1+len(labels)+len(labels)]
            data_1 = [int(x) for x in data_1]
            data_2 = [int(x) for x in data_2]
            sum_1 = sum(data_1)
            sum_2 = sum(data_2)
            q = sum_2 / sum_1
            data_1_2 = [x for x in data_1]
            data_2_2 = [int(x/q) for x in data_2]

            # remove classes with value < 5
            to_remove = []
            for i in range(len(data_1_2)):
                if data_1_2[i] < 5:
                    to_remove.append(i)
            for r in reversed(to_remove):
                data_1_2.pop(r)
                data_2_2.pop(r)

            if sum_1 == 0:
                data_1_1 = [0 for x in data_1]
            else:
                data_1_1 = [int(x/sum_1*100+0.5) for x in data_1]
            if sum_2 == 0:
                data_2_1 = [0 for x in data_2]
            else:
                data_2_1 = [int(x/sum_2*100+0.5) for x in data_2]

            # Statistical Tests
        
            # null hypothesis: data_2_1 the rest bugs
            #print(projects[p], percentage)
            (chisq, pp) = stats.chisquare(data_1_2, data_2_2)
            table_c[3][p+1] = chisq
            table_pc[3][p+1] = pp
            #print("chi-square:", chisq, ", p-value:", pp)
            (statistic, pp) = stats.mannwhitneyu(data_1, data_2)
            table_u[3][p+1] = statistic
            table_pu[3][p+1] = pp
            #print("mann-whitney u:", statistic, ", p-value:", pp)
    
            # Plots
            filename = "./results/reporters_non_security_bugs/plot_status_" + projects[p] + "_" + str(percentage) + ".png"
            utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                "Reporter Bugs", "Rest Bugs", "Status", percentage)          

    # Add type results
    for percentage in top_percentage:
        rows = []
        with open("./results/reporters_non_security_bugs/statistics_type_" + str(percentage) + ".csv", "r") as f:
            reader = csv.reader(f)
            for row in reader:
                rows.append(row)
        for p in range(len(projects)):
            collection = collections[p][0]
            if collection.find_one({"type": {"$exists":True}}):
                row_1 = rows[p*2]
                row_2 = rows[p*2+1]
                labels = [w.split("-")[0] for w in row_1[1:int(((len(row_1)-1)/2)+1)]]
                labels = list(dict.fromkeys(labels))
                data_1 = row_2[1:1+len(labels)]
                data_2 = row_2[1+len(labels):1+len(labels)+len(labels)]
                data_1 = [int(x) for x in data_1]
                data_2 = [int(x) for x in data_2]
                sum_1 = sum(data_1)
                sum_2 = sum(data_2)
                q = sum_2 / sum_1
                data_1_2 = [x for x in data_1]
                data_2_2 = [int(x/q) for x in data_2]

                # remove classes with value < 5
                to_remove = []
                for i in range(len(data_1_2)):
                    if data_1_2[i] < 5:
                        to_remove.append(i)
                for r in reversed(to_remove):
                    data_1_2.pop(r)
                    data_2_2.pop(r)

                if sum_1 == 0:
                    data_1_1 = [0 for x in data_1]
                else:
                    data_1_1 = [int(x/sum_1*100+0.5) for x in data_1]
                if sum_2 == 0:
                    data_2_1 = [0 for x in data_2]
                else:
                    data_2_1 = [int(x/sum_2*100+0.5) for x in data_2]

                # Statistical Tests

                # null hypothesis: data_2_1 the rest bugs
                #print(projects[p], percentage)
                (chisq, pp) = stats.chisquare(data_1_2, data_2_2)
                table_c[4][p+1] = chisq
                table_pc[4][p+1] = pp
                #print("chi-square:", chisq, ", p-value:", pp)
                (statistic, pp) = stats.mannwhitneyu(data_1, data_2)
                table_u[4][p+1] = statistic
                table_pu[4][p+1] = pp
                #print("mann-whitney u:", statistic, ", p-value:", pp)

                # Plots
                filename = "./results/reporters_non_security_bugs/plot_type_" + projects[p] + "_" + str(percentage) + ".png"
                utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                    "Reporter Bugs", "Rest Bugs", "Type", percentage)

    # Add key word results    
    for percentage in top_percentage:
        rows = []
        with open("./results/reporters_non_security_bugs/statistics_key_words_" + str(percentage) + ".csv", "r") as f:
            reader = csv.reader(f)
            for row in reader:
                rows.append(row)
        for p in range(len(projects)):
            row_1 = rows[p*2]
            row_2 = rows[p*2+1]
            labels = [w.split("-")[0] for w in row_1[1:int(((len(row_1)-1)/2))]]
            labels = list(dict.fromkeys(labels))
            data_1 = row_2[1:1+len(labels)]
            data_2 = row_2[1+len(labels)+1:1+len(labels)+len(labels)+1]
            data_1 = [int(x) for x in data_1]
            data_2 = [int(x) for x in data_2]
            sum_1 = int(row_2[1+len(labels)])
            sum_2 = int(row_2[1+len(labels)+1+len(labels)])
            q = sum_2 / sum_1
            data_1_2 = [x for x in data_1]
            data_2_2 = [int(x/q) for x in data_2]

            # remove classes with value < 5
            to_remove = []
            for i in range(len(data_1_2)):
                if data_1_2[i] < 5:
                    to_remove.append(i)
            for r in reversed(to_remove):
                data_1_2.pop(r)
                data_2_2.pop(r)

            data_1_1 = [float("{:.2f}".format((x/sum_1*100))) for x in data_1]
            data_2_1 = [float("{:.2f}".format((x/sum_2*100))) for x in data_2]

            # Statistical Tests

            # null hypothesis: data_2_1 the rest bugs
            #print(projects[p], percentage)
            (chisq, pp) = stats.chisquare(data_1_2, data_2_2)
            table_c[5][p+1] = chisq
            table_pc[5][p+1] = pp
            #print("chi-square:", chisq, ", p-value:", pp)
            (statistic, pp) = stats.mannwhitneyu(data_1, data_2)
            table_u[5][p+1] = statistic
            table_pu[5][p+1] = pp
            #print("mann-whitney u:", statistic, ", p-value:", pp)

            # Plots
            filename = "./results/reporters_non_security_bugs/plot_keywords_" + projects[p] + "_" + str(percentage) + ".png"
            utils.plot_non_sec_bugs_results(row_2[0], filename, labels, data_1_1, data_2_1, 
                "Reporter Bugs", "Rest Bugs", "Key Words", percentage)

    # Save tables
    df1 = pd.DataFrame(table_c)
    df1.to_csv("results/reporters_non_security_bugs/chisquare_test_statistics_1.csv")
    df2 = pd.DataFrame(table_pc)
    df2.to_csv("results/reporters_non_security_bugs/chisquare_test_statistics_p_value_1.csv")
    df3 = pd.DataFrame(table_u)
    df3.to_csv("results/reporters_non_security_bugs/mannwhitneyu_test_statistics_1.csv")
    df4 = pd.DataFrame(table_pu)
    df4.to_csv("results/reporters_non_security_bugs/mannwhitneyu_test_statistics_p_value_1.csv")

    # Some other statistics on the bug data
    reporters = dict()
    reporters_proj = [dict() for x in range(len(projects))]
    reporters_proj_all = [dict() for x in range(len(projects))]
    not_found_reps = []

    coll = rep_collection

    #with open("./../Project_2_CVE/project2cves.json") as jf:
    #    project2cves = json.load(jf)

    for i in range(len(projects)):
        if i == 0:
            project = "mozilla"
        elif i == 1:
            project = "apache"
        elif i == 2:
            project = "linux"
        elif i == 3:
            project = "php"

        with open(rep2non_cve_bugs_files[i]) as jf:
            rep2bugs = json.load(jf)
        with open(rep2cves_files[i]) as jf:
            rep2cves = json.load(jf)
        for rep in rep2bugs.keys():
            if coll.find_one({"name":rep}) == None:
                if not rep in not_found_reps:
                    not_found_reps.append(rep)
                    print("Reporter not found.")
            # only humans
            elif coll.find_one({"name":rep})['type'] == 'p' or coll.find_one({"name":rep})['type'] == ['p']:
                # if reporter not already in all reporter dict
                if not rep in reporters.keys():
                    reporters[rep] = 0
                reporters[rep] += len(rep2bugs[rep])
                
                cves = rep2cves[rep]
                in_project = False

                for cve in cves:
                    if cve in project2cves[project]:
                        in_project = True
                        break
                if in_project:
                    #if len(rep2bugs[rep]) > 0:
                    reporters_proj[i][rep] = len(rep2bugs[rep])
                        #if len(rep2bugs[rep]) > 500:
                        #    print(rep)

    results_str = ""

    results_str += "Number of cve reporters:" + str(len(list(reporters.keys()))) + "\n"
    sum_bugs_all = sum(reporters[x] for x in reporters.keys())
    sum_rep_all = sum(1 for x in reporters.keys() if reporters[x] != 0)
    sorted_reps = sorted(reporters.items(), key=lambda x : x[1])
    sorted_reps_wo_zero = list(filter(lambda x: x[1] != 0, sorted_reps))
    results_str += "Number of cve reporters with at least one bug:" + str(sum_rep_all)  + " ( " + str(sum_rep_all/len(list(reporters.keys()))) + " )\n"
    all_collections = []
    for coll in collections:
        all_collections.extend(coll)
    num_creators = utils.count_creators_bugs(all_collections)
    results_str += "Number of bug creators: " + str(num_creators) + "\n"
    results_str += "Percentage of creators not reportesr regarding all creators: " + str((num_creators-sum_rep_all)/num_creators) + " %\n"
    results_str += "Pecentage of cve reporters creating at least one bug regarding all creators: " + str(sum_rep_all/num_creators) + " %\n" 
    results_str += "Total number of bugs:" + str(sum_bugs_all)  + "\n"
    results_str += "Average number of bugs per reporter (only devided by reporters with at least 1 bug in one project): " + str(sum_bugs_all/sum_rep_all)  + "\n"
    results_str += "Average number of bugs per reporter (devided by all reporters of all projects):" + str(sum_bugs_all/len(list(reporters.keys())))  + "\n"
    results_str += "Median:" + str(sorted_reps_wo_zero[int(len(sorted_reps_wo_zero)/2)][1]) + "\n\n"
 
    for i in range(len(projects)):
        results_str += projects[i] + "\n"
        results_str += "Number of cve reporters:" + str(len(list(reporters_proj[i].keys())))  + "\n"
        sum_bugs_pro = sum(reporters_proj[i][x] for x in reporters_proj[i].keys())
        sum_rep_pro = sum(1 for x in reporters_proj[i].keys() if reporters_proj[i][x] != 0)
        sorted_reps = sorted(reporters_proj[i].items(), key=lambda x : x[1])
        sorted_reps_wo_zero = list(filter(lambda x: x[1] != 0, sorted_reps))
        results_str += "Number of cve reporters with at least one bug:" + str(sum_rep_pro)  + " ( " + str(sum_rep_pro/len(list(reporters_proj[i].keys()))) + " )\n"
        num_creators = utils.count_creators_bugs(collections[p])
        results_str += "Number of bug creators: " + str(num_creators) + "\n"
        results_str += "Percentage of creators not reportesr regarding all creators: " + str((num_creators-sum_rep_pro)/num_creators) + " %\n"
        results_str += "Pecentage of cve reporters creating at least one bug regarding all creators: " + str(sum_rep_pro/num_creators) + " %\n"
        results_str += "Total number of bugs:" + str(sum_bugs_pro)  + "\n"
        try:
            results_str += "Average number of bugs per reporter (only devided by reporters with at least 1 bug for the project): " + str(sum_bugs_pro/sum_rep_pro) + "\n"
        except:
            results_str += "Average number of bugs per reporter (only devided by reporters with at least 1 bug for the project): NaN \n"
        try:
            results_str += "Average number of bugs per reporter (devided by all reporters of all projects): " + str(sum_bugs_pro/len(list(reporters_proj[i].keys())))  + "\n"
        except:
            results_str += "Average number of bugs per reporter (devided by all reporters of all projects): NaN \n"
        try:
            results_str += "Median: " + str(sorted_reps_wo_zero[int(len(sorted_reps_wo_zero)/2)][1])  + "\n"
        except:
            results_str += "Median: NaN \n"
        with open(rep2cves_files[i]) as jf:
            rep2cves = json.load(jf)
        sum_rep_cves = sum(1 for x in rep2cves.keys() if len(rep2cves[x]) != 0)
        results_str += "Total number of reporters with at least one cve for this project: " + str(sum_rep_cves)  + "\n\n"

    for p in range(len(projects)):
        results_str += projects[p] + "\n"
        bug_with_commits = []
        counter = 0
        with open(bug2commits_files[p]) as jf:
            bug2commits = json.load(jf)
        for bug in bug2commits.keys():
            if len(bug2commits[bug]) > 0:
                bug_with_commits.append(str(bug))
            counter += 1
        results_str += "Number of bugs with at least one fixing commit: " + str(len(bug_with_commits)) + "\n"
        results_str += "Total number of bugs:" + str(counter) + "\n"
        
        with open(rep2non_cve_bugs_files[p]) as jf:
            rep2ncve_bugs = json.load(jf)
        with open(rep2cve_bugs_files[p]) as jf:
            rep2cve_bugs = json.load(jf)
    
        rep_fixed = []
        rep_not_fixed = []
        rest_fixed = []
        rest_not_fixed = []
        for bug in bug2commits.keys():
            found = False
            for rep in rep2ncve_bugs.keys():
                if int(bug) in rep2ncve_bugs[rep] or str(bug) in rep2ncve_bugs[rep] :
                    if str(bug) in bug_with_commits:
                        rep_fixed.append(bug)
                    else:
                        rep_not_fixed.append(bug)
                    found = True
                    break
            if not found:
                cve_bug = False
                for rep in rep2cve_bugs.keys():
                    if bug in rep2cve_bugs[rep]:
                        cve_bug = True
                        break
                if not cve_bug:
                    if bug in bug_with_commits:
                        rest_fixed.append(bug)
                    else:
                        rest_not_fixed.append(bug)
                
        results_str += "Reporter fixed:" + str(len(rep_fixed)) + "\n"
        results_str += "Reporter not fixed:" + str(len(rep_not_fixed)) + "\n"
        results_str += "Rest fixed:" + str(len(rest_fixed)) + "\n"
        results_str += "Rest not fixed:" + str(len(rest_not_fixed)) + "\n"

    with open("results/reporters_non_security_bugs/results.txt", "w") as f:
        f.write(results_str)

# Investigate reporters fixing their reported vulnerabilities and reporting new vulnerabilities after fixing a commit
def reporters_fixing_vulnerabilities(rep2info, repos, projects, cve2commits_files, cve2reps):
    
    # Create mapping from reporters to first fixing commit
    rep2firstfix = dict()

    # Create mappings from cves to commits for each project in a list in same order as projects
    cve2commit_projects = []

    for i in range(len(projects)):
        with open(cve2commits_files[i], 'r') as fp:
            cve2commit_projects.append(json.load(fp))

    # Create mapping from email to reporter
    email2rep = dict()
    for rep in rep2info:
        for email in rep2info[rep]['emails']:
            if email not in email2rep:
                email2rep[email] = [rep]
            else:
                email2rep[email].append(rep)

    results_str = ""

    for i in range(len(projects)):
        results_str += "Project: " + projects[i] + "\n"
        self_fixed_reps = []
        with_mapping = []
        target_repos = repos[i]
        results_str += "Target repositories: " + str(target_repos) + "\n"

        commit_dict = dict()

        # Create mapping from commit authors to number of commits
        author2commits = dict()

        for repo in target_repos:
            current_repo = Repo(repo)
            commits = list(current_repo.iter_commits('HEAD', max_count=1000000))

            
            for commit in commits:
                commit_dict[commit.hexsha] = commit

                author = commit.author.name
                email = commit.author.email
                if author not in author2commits:
                    author2commits[author] = dict()
                    author2commits[author]['emails'] = [email]
                    author2commits[author]['count'] = 1
                else:
                    if email not in author2commits[author]['emails']:
                        author2commits[author]['emails'].append(email)
                    author2commits[author]['count'] += 1

        results_str += "Number of commits in the repositories: " + str(len(list(commit_dict.keys()))) + "\n"    

        # Sort authors according number of commits
        sorted_author2commits = {k: v for k, v in sorted(author2commits.items(), key=lambda item: item[1]['count'], reverse = True)}
        self_fixed = []

        mapping = cve2commit_projects[i]

        for cve in mapping:
            sim_rep = None
            self_flag = False
            same_rep = []
            
            for commit_hash in mapping[cve]:
                try:
                    author = commit_dict[commit_hash].author.name
                    date = commit_dict[commit_hash].authored_date
                    
                    if cve not in with_mapping:
                        with_mapping.append(cve)
                except KeyError:
                    continue

                if author in rep2info:
                    #print('Found same names: ', author)
                    same_rep.append(author)
                    sim_rep = author
                    continue

                for email in author2commits[author]['emails']:
                    if email in email2rep:
                        #print('Found same emails: ', author, email2rep[email])
                        same_rep.append(email2rep[email][0])
                        sim_rep = email2rep[email][0]
                        break
                for rep in rep2info:
                    if len(author) > 5 and len(rep) > 5 and fuzz.ratio(author, rep)>90:
                        #print('Found similar names: ', author, rep)
                        same_rep.append(rep)
                        sim_rep = rep
                        break

                if sim_rep is not None and cve not in rep2info[sim_rep]['cves']:
                    if sim_rep not in rep2firstfix:
                        rep2firstfix[sim_rep] = date
                    else:
                        if date < rep2firstfix[sim_rep]:
                            rep2firstfix[sim_rep] = date

            for rep in same_rep:
                try:
                    if rep in cve2reps[cve]:
                        self_flag = True
                        if rep not in self_fixed_reps:
                            self_fixed_reps.append(rep)
                except:
                    pass

            if self_flag and cve not in self_fixed:
                self_fixed.append(cve)

        # See how many fixed what they reported and how many fixed something before their first report
        results_str += 'Self fixed commits: ' + str(len(self_fixed)) + '\n'
        results_str += 'Total with mapping: ' + str(len(with_mapping)) + '\n'
        results_str += 'Reporters with self fixes: ' + str(len(self_fixed_reps)) + '\n\n'

    results_str += 'Total reporters authored a CVE-fixing commit: ' + str(len(rep2firstfix)) + '\n'

    num_first_fix = 0
    timespan = []
    for rep in rep2firstfix:
        year_first_fix = int(time.asctime(time.gmtime(rep2firstfix[rep]))[-4:])
        year_first_report = 9999
        for cve in rep2info[rep]['cves']:
            year_rep = int(cve[4:8])
            if year_rep < year_first_report:
                year_first_report = year_rep

        if year_first_fix < year_first_report:
            timespan.append(year_first_report - year_first_fix)
            num_first_fix += 1

    results_str += 'Number of reporters fixing a vulnerability before reporting one: ' + str(num_first_fix) + '\n'

    with open("results/reporters_fixing_vulnerabilities/results.txt", "w") as f:
        f.write(results_str)

    fig1, ax1 = plt.subplots()
    ax1.set_title('Time between first fix and first report')
    ax1.boxplot(timespan)
    plt.savefig("./results/reporters_fixing_vulnerabilities/time_between_first_fix_and_report.pdf",format="pdf", bbox_inches="tight")
    plt.cla()
    plt.clf()
