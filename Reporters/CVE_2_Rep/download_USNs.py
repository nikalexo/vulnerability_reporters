import requests
import re
import json
import sys
from pymongo import MongoClient

# insert at 1, 0 is the script path (or '' in REPL)
sys.path.insert(1, './../../../cve-search/')

import lib.DatabaseLayer as db

client = MongoClient()
db1 = client.cvedb
collection1 = db1.cves

cve = collection1.find_one({"id": "CVE-2019-15891"})

if cve == '':
    logging.warning('CVE not found in mongodb')


# Load all cve ids
with open("./../../Mappings/Project_2_CVE/project2cves.json") as jf:
    project2cves = json.load(jf)

cve_list = []
for project in ['mozilla-suite', 'apache', 'linux', 'php']:
    cve_list.extend(project2cves[project])

cve_list = list(set(cve_list))

# Load full cves
full_cves = []
for cve in cve_list:
    item = collection1.find_one({"id": cve})
    if item != None:
        full_cves.append(item)

# Find already fetched USNs
try:
    with open("./usn2info.json") as jf:
        usn2info = json.load(jf)
    print("Opened all already downloaded USNs!")
    print(list(usn2info.keys()))
except:
    usn2info = dict()
    print("No local USNs found!")

# Get USN references in cves
sources_cve = dict()
for cve in full_cves:
    references = cve['references']

    for ref in references:
        url_usn = 'usn.ubuntu.com/'
        to_search = r'((?<=' + url_usn.replace('?', '\?').replace('=', '\=') + ')'
        to_search += ').+'
        m = re.search(to_search, ref)
        try:
            usn_ref=m.group(0)
            sources_cve[cve['id']] = usn_ref
        except AttributeError:
            url_usn = 'ubuntu.com/usn/'
            to_search = r'((?<=' + url_usn.replace('?', '\?').replace('=', '\=') + ')'
            to_search += ').+'
            m = re.search(to_search, ref)
            try:
                usn_ref=m.group(0)
                sources_cve[cve['id']] = usn_ref
            except AttributeError:
                pass

# Download USNs
unique_usn = []
for cve in sources_cve:
    usn=sources_cve[cve]
    if usn not in unique_usn and usn != '0':
        unique_usn.append(usn)

url_usn1 = 'https://usn.ubuntu.com/'
url_usn2 = 'https://ubuntu.com/usn/'

# This regex uses positive lookahead to try and match the discoverer
regex = r'[a-zA-Z"](\w| |\'|"|-)+(?=( discovered)|( reported)|( found)|( noticed)|( provided a)|( resolved an))'
exceptions = r'was$|been$|were$'
cve_reg = r'(?<=\()(CVE-(\d|-)*)(?=\))'

for usn_id in unique_usn:
    if usn_id not in usn2info:
        try:
            URL = url_usn1+usn_id
            #print('Trying URL: ',URL)
            temp = requests.get(URL)
            #print('Reply: ',temp)
            if temp.status_code != 200:
                URL = url_usn2+usn_id
                #print('Trying URL: ',URL)
                temp = requests.get(URL)
            usn2info[usn_id] = temp.text
            
        except AttributeError:
            print('Trouble getting USN', usn_id)
            continue

with open("./usn2info.json", "w") as jf:
    json.dump(usn2info, jf)

print("Finished!")