"""
Parses html files to extract bugs saving in json files.
"""

import xml.etree.ElementTree as ET
import HTMLparser as parser
import traceback
import multiprocessing
import time
import wget
import json
import sys
import os
import io

root = ET.parse('../../config.xml')

CONFIG = "s"
FOLDER = "bugs"
MAX_BUG_ID = int(root.find("projects").find('.//product[@name=\'php\']').find("bugs").find("max-bug").text)
NUM_PROCESSES = int(multiprocessing.cpu_count() * 3/4)
DATA_LENGTH = 15     


def main():
    if len(sys.argv) < 2:
        print("usage: python parse.py [OPTION]..")
        print("-s:\tstandard config - one output json file and use of 3/4 of available cores as processes")
        print("-m:\tmodified config - number of created processes and number of output json files")
        print("-p:\tfolder to store the output json files (default: 'bugs')")
        sys.exit()

    global CONFIG
    global FOLDER
    global NUM_PROCESSES
    try:
        if "-m" in sys.argv:
            index = sys.argv.index("-m")
            CONFIG = "m"
            NUM_PROCESSES = int(sys.argv[index+1])
    except:
        exit("Error: Something went wrong with the argument for option -m")
    try:
        if "-p" in sys.argv:
            index = sys.argv.index("-p")
            FOLDER = sys.argv[index+1]
    except:
        exit("Error: Option -p found but no name of folder is given!")

    if CONFIG == "s":
        create_folder_if_not_exists(FOLDER)
        parse_bugs_standard()
    elif CONFIG == "m":
        create_folder_if_not_exists(FOLDER)
        parse_bugs_modified()

def parse_bugs_standard():
    bug_data = multiprocessing.Manager().dict()

    jobs = []
    for i in range(NUM_PROCESSES):
        start = int(MAX_BUG_ID/NUM_PROCESSES * i) + 1
        end = int(min(MAX_BUG_ID/NUM_PROCESSES * (i + 1)+1, MAX_BUG_ID+1))
        p = multiprocessing.Process(target=parse_bugs_standard_proccess, args=(start, end, bug_data))
        jobs.append(p)
        p.start()

    while(True):
        time.sleep(1)
        running = False
        for j in jobs:
            if j.is_alive():
                running = True
                break
        if(not running):
            break
        
    #print("Successfully parsed all HTML files!")

    create_json(bug_data, FOLDER + "/php.json")


def parse_bugs_standard_proccess(start, end, return_dict):
    # print("Start bug_id: " + str(start) + ", End bug_id: " + str(end-1))
    for x in range(start, end):
        try:
            with open("bugs_html/bug_" + str(x) + ".html") as f:
                bug = f.read()
        except IOError:
            print("Warning: File 'bugs_html/bug_" + str(x) + ".html" + "' not found.")
            bug = ""

        # print("Starting parsing ...")
        data = parser.parse_all(bug)
        
        # check on meaningful parsed data
        if data[0] == "":
            #print("ATTENTION! Bug '" + str(x) + "' not found!")
            return_dict[x] = None
        elif len(data) != DATA_LENGTH:
            print("ATTENTION! 'data' array has not the correct length! data:", data)
            return_dict[x] = None
        else:
            return_dict[x] = data

def parse_bugs_modified():
    jobs = []
    for i in range(NUM_PROCESSES):
        start = int(MAX_BUG_ID/NUM_PROCESSES * i) + 1
        end = int(min(MAX_BUG_ID/NUM_PROCESSES * (i + 1)+1, MAX_BUG_ID+1))
        p = multiprocessing.Process(target=parse_bugs_modified_proccess, args=(start, end, i))
        jobs.append(p)
        p.start()

    while(True):
        time.sleep(1)
        running = False
        for j in jobs:
            if j.is_alive():
                running = True
                break
        if(not running):
            break

    #print("Successfully parsed all HTML files!")

def parse_bugs_modified_proccess(start, end, num):
    bug_data = multiprocessing.Manager().dict()
    parse_bugs_standard_proccess(start, end, bug_data)
    create_json(bug_data, FOLDER + "/php_" + str(num) + ".json")
    
def create_json(bug_data, path):
    bugs = dict()
    bugs["bugs"] = []
    
    # product means package
    fields = ["id", "summary", "creation_time", "modification_time", "creator", "status", "product", "version", "os", "private_report", "cve-id", "type", "assigned", "description"]
    
    data = dict(bug_data)
    
    for bug_id in data.keys():
        if data[bug_id] != None:
            bug_dict = dict()
            for i in range(len(fields)):
                try:
                    bug_dict[fields[i]] = data[bug_id][i]
                except:
                    print("Error")
            bug_dict["comments"] = create_dict_comments(data[bug_id][-1])
            bugs["bugs"].append(bug_dict)
    
    with open(path, "w") as jf:
        json.dump(bugs, jf)

    #print("Successfully created json file!")

def create_dict_comments(comments):
    comments_list = []
    fields = ["time", "creator", "text"]
    for comment in comments:
        comment_dict = dict()
        for i in range(len(fields)):
            try:
                comment_dict[fields[i]] = comment[i]
            except:
                print("Error")
        comments_list.append(comment_dict)
    return comments_list

def create_folder_if_not_exists(folder):
    if not os.path.exists("./" + folder + "/"):
        os.mkdir("./" + folder)
        
main()
